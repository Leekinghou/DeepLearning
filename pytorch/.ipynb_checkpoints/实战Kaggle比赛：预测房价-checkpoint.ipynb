{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fecc7f9e",
   "metadata": {},
   "source": [
    "# 实战Kaggle比赛：预测房价\n",
    "\n",
    "房价预测比赛是一个很好的起点。这个数据是相当通用的，不会需要使用带特殊结构的模型（就像音频或视频可能需要的那样）。此数据集由Bart de Cock于2011年收集 [DeCock, 2011] ，涵盖了2006-2010年期间亚利桑那州埃姆斯市的房价。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1082fe6",
   "metadata": {},
   "source": [
    "##  我们实现几个函数来方便下载数据\n",
    "首先，我们维护字典DATA_HUB，其将数据集名称的字符串映射到数据集相关的**二元组**上，这个二元组包含数据集的url和验证文件完整性的sha-1密钥。所有这样的数据集都托管在地址为DATA_URL的站点上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ae70b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import os\n",
    "import tarfile\n",
    "import zipfile\n",
    "import requests\n",
    "\n",
    "#@save\n",
    "DATA_HUB = dict()\n",
    "DATA_URL = 'http://d2l-data.s3-accelerate.amazonaws.com/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bff140",
   "metadata": {},
   "source": [
    "下面的download函数用来下载数据集，将数据集缓存在本地目录（默认情况下为../data）中，并返回下载文件的名称。如果缓存目录中已经存在此数据集文件，并且其sha-1与存储在DATA_HUB中的相匹配，我们将使用缓存的文件，以避免重复的下载。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee9778fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(name, cache_dir=os.path.join('..', 'data')):  #@save\n",
    "    \"\"\"下载一个DATA_HUB中的文件，返回本地文件名。\"\"\"\n",
    "    assert name in DATA_HUB, f\"{name} 不存在于 {DATA_HUB}.\"\n",
    "    url, sha1_hash = DATA_HUB[name]\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    fname = os.path.join(cache_dir, url.split('/')[-1])\n",
    "    if os.path.exists(fname):\n",
    "        sha1 = hashlib.sha1()\n",
    "        with open(fname, 'rb') as f:\n",
    "            while True:\n",
    "                data = f.read(1048576)\n",
    "                if not data:\n",
    "                    break\n",
    "                sha1.update(data)\n",
    "        if sha1.hexdigest() == sha1_hash:\n",
    "            return fname  # Hit cache\n",
    "    print(f'正在从{url}下载{fname}...')\n",
    "    r = requests.get(url, stream=True, verify=True)\n",
    "    with open(fname, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf0a37",
   "metadata": {},
   "source": [
    "我们还实现了两个额外的实用函数：一个是下载并解压缩一个zip或tar文件，另一个是将本书中使用的所有数据集从DATA_HUB下载到缓存目录中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "868d1c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_extract(name, folder=None):  #@save\n",
    "    \"\"\"下载并解压zip/tar文件。\"\"\"\n",
    "    fname = download(name)\n",
    "    base_dir = os.path.dirname(fname)\n",
    "    data_dir, ext = os.path.splitext(fname)\n",
    "    if ext == '.zip':\n",
    "        fp = zipfile.ZipFile(fname, 'r')\n",
    "    elif ext in ('.tar', '.gz'):\n",
    "        fp = tarfile.open(fname, 'r')\n",
    "    else:\n",
    "        assert False, '只有zip/tar文件可以被解压缩。'\n",
    "    fp.extractall(base_dir)\n",
    "    return os.path.join(base_dir, folder) if folder else data_dir\n",
    "\n",
    "def download_all():  #@save\n",
    "    \"\"\"下载DATA_HUB中的所有文件。\"\"\"\n",
    "    for name in DATA_HUB:\n",
    "        download(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100fea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果pandas没有被安装，请取消下一句的注释。\n",
    "# !pip install pandas\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7633a3cc",
   "metadata": {},
   "source": [
    "为方便起见，我们可以使用上面定义的脚本下载并缓存Kaggle房屋数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7934dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_HUB['kaggle_house_train'] = (  #@save\n",
    "    DATA_URL + 'kaggle_house_pred_train.csv',\n",
    "    '585e9cc93e70b39160e7921475f9bcd7d31219ce')\n",
    "\n",
    "DATA_HUB['kaggle_house_test'] = (  #@save\n",
    "    DATA_URL + 'kaggle_house_pred_test.csv',\n",
    "    'fa19780a7b011d9b009e8bff8e99922a8ee2eb90')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c97ef04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_train.csv下载../data/kaggle_house_pred_train.csv...\n",
      "正在从http://d2l-data.s3-accelerate.amazonaws.com/kaggle_house_pred_test.csv下载../data/kaggle_house_pred_test.csv...\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(download('kaggle_house_train'))\n",
    "test_data = pd.read_csv(download('kaggle_house_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a5cb2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "894d61e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n",
      "0   1          60       RL         65.0       WD        Normal     208500\n",
      "1   2          20       RL         80.0       WD        Normal     181500\n",
      "2   3          60       RL         68.0       WD        Normal     223500\n",
      "3   4          70       RL         60.0       WD       Abnorml     140000\n",
      "4   5          60       RL         84.0       WD        Normal     250000\n",
      "5   6          50       RL         85.0       WD        Normal     143000\n",
      "6   7          20       RL         75.0       WD        Normal     307000\n",
      "7   8          60       RL          NaN       WD        Normal     200000\n",
      "8   9          50       RM         51.0       WD       Abnorml     129900\n",
      "9  10         190       RL         50.0       WD        Normal     118000\n"
     ]
    }
   ],
   "source": [
    "print(train_data.iloc[0:10, [0, 1, 2, 3, -3, -2, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa73477",
   "metadata": {},
   "source": [
    "我们可以看到，在每个样本中，第一个特征是ID，这有助于模型识别每个训练样本。虽然这很方便，但它不携带任何用于预测的信息。因此，在将数据提供给模型之前，我们将其从数据集中删除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "224f8ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff83bb",
   "metadata": {},
   "source": [
    "##  数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc6dbf",
   "metadata": {},
   "source": [
    "![image.png](https://pic.rmb.bdstatic.com/bjh/7c4bbd708467aabb14a44a8ebacae9cc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94da79ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(\n",
    "    lambda x: (x - x.mean()) / (x.std()))\n",
    "# 在标准化数据之后，所有数据都意味着消失，因此我们可以将缺失值设置为0\n",
    "all_features[numeric_features] = all_features[numeric_features].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f224b72b",
   "metadata": {},
   "source": [
    "![image.png](https://pic.rmb.bdstatic.com/bjh/d98fb9a070dbe7e31d674c949df71590.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d356c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 331)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `Dummy_na=True` 将“na”（缺失值）视为有效的特征值，并为其创建指示符特征。\n",
    "all_features = pd.get_dummies(all_features, dummy_na=True)\n",
    "all_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255a3d9",
   "metadata": {},
   "source": [
    "你可以看到，此转换会将特征的数量从79个增加到331个。最后，通过values属性，我们可以从pandas格式中提取NumPy格式，并将其转换为张量表示用于训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "575d2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = train_data.shape[0]\n",
    "train_features = torch.tensor(all_features[:n_train].values, dtype=d2l.float32)\n",
    "test_features = torch.tensor(all_features[n_train:].values, dtype=d2l.float32)\n",
    "train_labels = torch.tensor(\n",
    "    train_data.SalePrice.values.reshape(-1, 1), dtype=d2l.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4c77c3",
   "metadata": {},
   "source": [
    "## 训练\n",
    "首先，我们训练一个带有损失平方的线性模型。毫不奇怪，我们的线性模型不会让我们在竞赛中获胜，但线性模型提供了一种健全性检查，以查看数据中是否存在有意义的信息。如果我们在这里不能做得比随机猜测更好，那么我们很可能存在数据处理错误。如果一切顺利，线性模型将作为基线模型，让我们直观地知道简单的模型离报告最好的模型有多近，让我们感觉到我们应该从更酷炫的模型中获得多少收益。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88b74379",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "in_features = train_features.shape[1]\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential(nn.Linear(in_features,1))\n",
    "    return net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f76bf0",
   "metadata": {},
   "source": [
    "![image.png](https://pic.rmb.bdstatic.com/bjh/1c07e74c087d865a480a2cde208f2dd1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd888a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
